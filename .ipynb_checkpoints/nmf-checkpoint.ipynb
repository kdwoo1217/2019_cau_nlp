{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import scipy as sp;\n",
    "import sys;\n",
    "import pprint\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords;\n",
    "import nltk;\n",
    "\n",
    "from gensim.models import ldamodel\n",
    "from gensim.models import nmf\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "\n",
    "import pickle;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/kdwoo/Documents/Jupyter/2019_CAU_NLP/abcnews-date-text.csv', error_bad_lines=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['publish_date'] = pd.to_datetime(data['publish_date'].astype(str), format = '%Y%m%d')\n",
    "data['publish_date'] = pd.DatetimeIndex(data['publish_date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data[['headline_text']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data['headline_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_nostops = pd.Series(data_words_nostops)\n",
    "data_lemmatized = data_words_nostops.apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_words_nostops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])  # 불용어처리\n",
    "\n",
    "#  빈도수 높은 키워드 처리\n",
    "stop_words.extend([ 'from', 'subject', 're', 'edu', 'use', 'home', 'hunter', 'help', 'time', 'national', 'build', 'end', 'bid', 'cup', 'un', 'come', 'join', 'across','Italy', 'grind', 'asian', 'sa', 'miss', 'one', 'use', 'three', 'Darwin', 'vic', 'number', 'may', 'start', 'law', 'way', 'communities', 'order', 'check', 'major', 'india', 'focus', 'form', 'journalist', 'milk', 'nz', 'rank', 'cook', 'egypt', 'New', 'year', 'force', 'fail', 'dead', 'was', 'fruit', 'philippines','nick'])\n",
    "stop_words.extend(['fire', 'new', 'world', 'boat', 'turn', 'around', 'well', 'Find', 'two', 'adelaide', 'first', 'make', 'body', 'probe', 'outback', 'baby', 'David', 'street', 'mass', 'hotel', 'say', 'open', 'go', 'welcome', 'announce', 'level', 'allow', 'highest','queensland', 'kill', 'crash', 'road', 'record', 'nt', 'hit', 'plane', 'toll', 'suspend', 'peninsula', 'afghan', 'recovery','man', 'perth', 'flood', 'people', 'still', 'supply', 'siege', 'spark', 'summer', 'Michael', 'ops', 'large', 'flash', 'view', 'attack', 'back', 'mine', 'deal', 'fan', 'celebrate', 'target', 'hill', 'party', 'reveal', 'terrorism', 'video', 'pressure', 'remember', 'korea', 'indian', 'millions', 'drill', 'country', 'hour', 'podcast', 'leaders', 'thursday', 'abbott', 'tony',  'shorten', 'sach', 'day', 'years', 'show', 'teen', 'heat', 'issue', 'free', 'australias', 'asbestos', 'compete','South', 'china', 'talk', 'appeal', 'labor', 'plant', 'peter', 'allegedly', 'begin', 'try', 'ice', 'native', 'alcohol', 'Australia', 'league', 'live', 'launch',  'benefit', 'update', 'stream', 'cabinet', 'document', 'bob','Test', 'drug', 'brisbane', 'british', 'double', 'ebola', 'Wa', 'research', 'expansion', 'ready', 'old', 'release', 'paper', 'see'])\n",
    "\n",
    "# 그 아래에서  빈도수 높은 키워드 처리\n",
    "stop_words.extend(['call',  'queensland', 'melbourne', 'perth', 'thousands', 'alert', 'reveal', 'spark', 'amid', 'australian',  'brisbane', 'western', 'high', 'fan', 'prepare', 'british', 'battle', 'beach', 'wa', 'take',  'box', 'could',  'search', 'black', 'michael', 'week','man', 'day' ,'country', 'new', 'old', 'test',  'force', 'release', 'miss','say', 'south', 'was','fire', 'victoria', 'build','australia', 'court','find', 'fall','mine', 'darwin', 'break', 'record', 'david', 'reflect', 'remember','adelaide', 'show'])\n",
    "\n",
    "#  빈도수 높은 키워드 처리\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use',' court', 'home',' council', 'hunter', 'help', 'time', 'injure', 'national', 'build', 'end', 'bid', 'cup', 'un', 'come', 'security', 'volunteer', 'ship', 'crew', 'crowd', 'join', 'helicopter', 'across', 'museum', 'Italy', 'grind', 'asian', 'sa', 'miss', 'one', 'die', 'use', 'three', 'Darwin', 'vic', 'number', 'may', 'start', 'law', 'way', 'communities', 'order', 'check', 'major', 'india', 'focus', 'form', 'journalist', 'milk', 'nz', 'rank', 'cook', 'egypt', 'New', 'year', 'force', 'fail', 'dead', 'was', 'farmer', 'fruit', 'philippines', 'injury', 'nick'])\n",
    "stop_words.extend(['fire', 'new', 'hobart', 'rural', 'world', 'boat', 'turn', 'flight', 'around', 'well', 'Find', 'two', 'adelaide', 'murder', 'first', 'make', 'body', 'probe', 'outback', 'tourism', 'baby', 'David', 'street', 'mass', 'hotel', 'Police', 'say', 'open', 'dog', 'go', 'welcome', 'president', 'announce', 'level', 'allow', 'highest','queensland', 'kill', 'crash', 'road', 'record', 'nt', 'hit', 'plane', 'toll', 'suspend', 'peninsula', 'afghan', 'recovery','man', 'perth', 'flood', 'people', 'prison', 'still', 'supply', 'siege', 'spark', 'summer', 'Michael', 'ops', 'large', 'flash', 'view', 'attack', 'back', 'mine', 'deal', 'fan', 'celebrate', 'target', 'hill', 'party', 'reveal', 'terrorism', 'video', 'pressure', 'remember', 'korea', 'indian', 'millions', 'drill', 'country', 'hour', 'podcast', 'leaders', 'thursday', 'abbott', 'tony', 'policy', 'agricultural', 'shorten', 'sach', 'day', 'years', 'show', 'teen', 'heat', 'sport', 'issue', 'free', 'australias', 'asbestos', 'compete','South', 'china', 'talk', 'appeal', 'labor', 'plant', 'peter', 'allegedly', 'begin', 'try', 'ice', 'native', 'alcohol', 'Australia', 'league', 'live', 'launch', 'campaign', 'benefit', 'update', 'stream', 'cabinet', 'document', 'bob','Test', 'drug', 'brisbane', 'international', 'british', 'double', 'treat', 'patient', 'ebola', 'Wa', 'bushfire', 'research', 'expansion', 'ready', 'old', 'release', 'paper', 'see'])\n",
    "\n",
    "# 그 아래에서  빈도수 높은 키워드 처리\n",
    "stop_words.extend(['call',  'queensland', 'melbourne', 'perth', 'thousands', 'alert', 'reveal', 'spark', 'amid', 'illegal', 'australian', 'price',  'brisbane', 'western', 'high', 'fan', 'prepare', 'british', 'battle', 'beach', 'wa', 'take',  'box', 'could',  'search', 'black', 'michael', 'week','man', 'day' ,'country', 'new', 'old', 'police', 'test',  'force', 'release', 'hobart', 'council', 'die', 'miss','say', 'south', 'was','fire', 'victoria', 'build','australia', 'court','find', 'fall','mine','attack', 'darwin', 'break', 'record', 'david', 'reflect', 'remember','adelaide', 'show'])\n",
    "stop_words.extend(['set','cut','put','us','january','febrary','april','may','june','july', 'august', 'november', 'september', 'october', 'december', 'july', 'march', 'wednesday', 'february','monday','tuesday','wednesday','thursday','friday','sunday','get','act','sydney','iraq'])\n",
    "#stop_words\n",
    "\n",
    "# 2019-06-13\n",
    "stop_words.extend(['govt', 'plan', 'continue', 'charge', 'face', 'five', 'qld'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized = remove_stopwords(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data\n",
    "temp['lemmatize'] = data_lemmatized\n",
    "for i in range(15):\n",
    "    globals()['trend{}'.format(i+2003)] = temp.loc[temp.publish_date == i+2003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_list = [trend2003, trend2004, trend2005, trend2006, trend2007, trend2008, trend2009, trend2010,\n",
    "              trend2011, trend2012, trend2013, trend2014, trend2015, trend2016, trend2017]\n",
    "#print(trend_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(data_text, open('2003_data_text.dat', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_headlines = [value[0] for value in data_text.iloc[0:].values];\n",
    "#print(train_headlines[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 20;\n",
    "lemmatized = list(trend2006['lemmatize']) # 확인 년도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(lemmatized)\n",
    "texts = lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_headlines_sentences = [' '.join(text) for text in train_headlines]\n",
    "#print(train_headlines_sentences[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', max_features=len(lemmatized));\n",
    "x_counts = vectorizer.fit_transform(' '.join(text) for text in list(trend2006['lemmatize']));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False);\n",
    "x_tfidf = transformer.fit_transform(x_counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtfidf_norm = normalize(x_tfidf, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = gensim.models.nmf.Nmf(corpus,\n",
    "                                   num_topics,\n",
    "                                   id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.102*\"pm\" + 0.046*\"closer\" + 0.033*\"defend\" + 0.016*\"return\" + '\n",
      "  '0.016*\"cyclone\" + 0.013*\"case\" + 0.013*\"lose\" + 0.012*\"bali\" + 0.011*\"pay\" '\n",
      "  '+ 0.010*\"workers\"'),\n",
      " (1,\n",
      "  '0.068*\"consider\" + 0.059*\"residents\" + 0.031*\"rescue\" + 0.026*\"game\" + '\n",
      "  '0.024*\"nsw\" + 0.017*\"group\" + 0.014*\"rain\" + 0.013*\"safety\" + 0.012*\"team\" '\n",
      "  '+ 0.008*\"move\"'),\n",
      " (2,\n",
      "  '0.121*\"reject\" + 0.047*\"fear\" + 0.028*\"group\" + 0.023*\"claim\" + 0.019*\"car\" '\n",
      "  '+ 0.015*\"work\" + 0.010*\"indigenous\" + 0.009*\"bomb\" + 0.009*\"question\" + '\n",
      "  '0.009*\"laws\"'),\n",
      " (3,\n",
      "  '0.156*\"report\" + 0.034*\"mp\" + 0.019*\"urge\" + 0.018*\"tax\" + 0.018*\"support\" '\n",
      "  '+ 0.017*\"offer\" + 0.011*\"final\" + 0.010*\"play\" + 0.008*\"bird\" + '\n",
      "  '0.007*\"flu\"'),\n",
      " (4,\n",
      "  '0.187*\"health\" + 0.099*\"service\" + 0.043*\"mental\" + 0.034*\"urge\" + '\n",
      "  '0.018*\"indigenous\" + 0.009*\"opposition\" + 0.007*\"ama\" + 0.006*\"push\" + '\n",
      "  '0.006*\"action\" + 0.006*\"need\"'),\n",
      " (5,\n",
      "  '0.225*\"seek\" + 0.026*\"opposition\" + 0.026*\"accuse\" + 0.009*\"support\" + '\n",
      "  '0.009*\"group\" + 0.008*\"witness\" + 0.006*\"feedback\" + 0.006*\"public\" + '\n",
      "  '0.005*\"laws\" + 0.005*\"answer\"'),\n",
      " (6,\n",
      "  '0.100*\"jail\" + 0.065*\"minister\" + 0.040*\"inquiry\" + 0.016*\"former\" + '\n",
      "  '0.016*\"want\" + 0.015*\"awb\" + 0.009*\"death\" + 0.009*\"cole\" + 0.009*\"term\" + '\n",
      "  '0.006*\"oil\"'),\n",
      " (7,\n",
      "  '0.059*\"death\" + 0.045*\"investigate\" + 0.043*\"sex\" + 0.041*\"accuse\" + '\n",
      "  '0.038*\"assault\" + 0.031*\"ban\" + 0.029*\"child\" + 0.013*\"rise\" + '\n",
      "  '0.009*\"abuse\" + 0.008*\"promise\"'),\n",
      " (8,\n",
      "  '0.149*\"boost\" + 0.058*\"rise\" + 0.023*\"tas\" + 0.021*\"mp\" + 0.020*\"concern\" + '\n",
      "  '0.018*\"rate\" + 0.012*\"pay\" + 0.011*\"indigenous\" + 0.011*\"centre\" + '\n",
      "  '0.008*\"look\"'),\n",
      " (9,\n",
      "  '0.093*\"hospital\" + 0.055*\"doctor\" + 0.047*\"bird\" + 0.044*\"flu\" + '\n",
      "  '0.031*\"tas\" + 0.017*\"guilty\" + 0.014*\"case\" + 0.014*\"confirm\" + '\n",
      "  '0.013*\"plead\" + 0.010*\"close\"'),\n",
      " (10,\n",
      "  '0.166*\"win\" + 0.040*\"lead\" + 0.014*\"award\" + 0.010*\"victory\" + '\n",
      "  '0.009*\"aussies\" + 0.007*\"election\" + 0.006*\"final\" + 0.006*\"top\" + '\n",
      "  '0.006*\"aussie\" + 0.006*\"title\"'),\n",
      " (11,\n",
      "  '0.116*\"coast\" + 0.101*\"gold\" + 0.035*\"north\" + 0.017*\"game\" + 0.014*\"power\" '\n",
      "  '+ 0.012*\"storm\" + 0.011*\"rise\" + 0.010*\"west\" + 0.009*\"cyclone\" + '\n",
      "  '0.008*\"farmers\"'),\n",
      " (12,\n",
      "  '0.144*\"claim\" + 0.044*\"blaze\" + 0.035*\"market\" + 0.022*\"firefighters\" + '\n",
      "  '0.015*\"farmers\" + 0.013*\"lose\" + 0.012*\"title\" + 0.011*\"safety\" + '\n",
      "  '0.010*\"win\" + 0.010*\"hold\"'),\n",
      " (13,\n",
      "  '0.082*\"house\" + 0.061*\"aust\" + 0.036*\"concern\" + 0.017*\"school\" + '\n",
      "  '0.011*\"troop\" + 0.010*\"fight\" + 0.010*\"fatal\" + 0.008*\"timor\" + '\n",
      "  '0.008*\"name\" + 0.008*\"air\"'),\n",
      " (14,\n",
      "  '0.231*\"warn\" + 0.020*\"prompt\" + 0.011*\"threat\" + 0.010*\"nuclear\" + '\n",
      "  '0.009*\"death\" + 0.008*\"safety\" + 0.007*\"public\" + 0.007*\"cyclone\" + '\n",
      "  '0.006*\"iran\" + 0.006*\"israel\"'),\n",
      " (15,\n",
      "  '0.190*\"change\" + 0.025*\"climate\" + 0.022*\"mp\" + 0.018*\"ir\" + 0.009*\"laws\" + '\n",
      "  '0.008*\"strike\" + 0.007*\"rule\" + 0.006*\"work\" + 0.006*\"study\" + '\n",
      "  '0.006*\"media\"'),\n",
      " (16,\n",
      "  '0.256*\"fund\" + 0.016*\"federal\" + 0.011*\"budget\" + 0.010*\"school\" + '\n",
      "  '0.010*\"workers\" + 0.009*\"centre\" + 0.008*\"raise\" + 0.008*\"power\" + '\n",
      "  '0.007*\"push\" + 0.006*\"fight\"'),\n",
      " (17,\n",
      "  '0.235*\"urge\" + 0.029*\"public\" + 0.015*\"arrest\" + 0.012*\"suspect\" + '\n",
      "  '0.011*\"rule\" + 0.010*\"shoot\" + 0.009*\"trial\" + 0.007*\"farmers\" + '\n",
      "  '0.005*\"child\" + 0.005*\"link\"'),\n",
      " (18,\n",
      "  '0.084*\"meet\" + 0.032*\"nsw\" + 0.028*\"minister\" + 0.021*\"school\" + '\n",
      "  '0.018*\"prompt\" + 0.018*\"train\" + 0.017*\"move\" + 0.012*\"job\" + '\n",
      "  '0.012*\"support\" + 0.009*\"top\"'),\n",
      " (19,\n",
      "  '0.233*\"water\" + 0.017*\"restrictions\" + 0.014*\"park\" + 0.013*\"recycle\" + '\n",
      "  '0.013*\"rise\" + 0.011*\"trade\" + 0.011*\"return\" + 0.009*\"mayor\" + '\n",
      "  '0.008*\"save\" + 0.008*\"river\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(nmf_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nmf_model, open('2004_20topic_data_text.dat', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kdwoo/Documents/Jupyter/2019_CAU_NLP/nmf_data/nmf_20_data/2003_20topic_data_text.dat', 'rb') as f:\n",
    "    data_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.175*\"support\" + 0.019*\"seek\" + 0.015*\"big\" + 0.013*\"group\" + '\n",
      "  '0.010*\"offer\" + 0.009*\"strike\" + 0.009*\"centre\" + 0.009*\"community\" + '\n",
      "  '0.007*\"business\" + 0.007*\"school\"'),\n",
      " (1,\n",
      "  '0.240*\"claim\" + 0.045*\"reject\" + 0.009*\"title\" + 0.007*\"abuse\" + '\n",
      "  '0.005*\"investigate\" + 0.005*\"victory\" + 0.004*\"sars\" + 0.004*\"hear\" + '\n",
      "  '0.004*\"group\" + 0.004*\"opposition\"'),\n",
      " (2,\n",
      "  '0.160*\"warn\" + 0.058*\"anti\" + 0.039*\"protest\" + 0.017*\"protesters\" + '\n",
      "  '0.015*\"war\" + 0.008*\"travel\" + 0.008*\"rally\" + 0.007*\"terror\" + '\n",
      "  '0.006*\"threat\" + 0.006*\"arrest\"'),\n",
      " (3,\n",
      "  '0.160*\"pm\" + 0.023*\"troop\" + 0.015*\"north\" + 0.014*\"palestinian\" + '\n",
      "  '0.013*\"west\" + 0.012*\"decision\" + 0.010*\"head\" + 0.010*\"hear\" + '\n",
      "  '0.009*\"farmers\" + 0.008*\"clash\"'),\n",
      " (4,\n",
      "  '0.091*\"health\" + 0.074*\"minister\" + 0.064*\"fund\" + 0.063*\"meet\" + '\n",
      "  '0.021*\"troop\" + 0.016*\"service\" + 0.008*\"boost\" + 0.007*\"hospital\" + '\n",
      "  '0.007*\"discuss\" + 0.007*\"group\"'),\n",
      " (5,\n",
      "  '0.097*\"lead\" + 0.046*\"job\" + 0.027*\"tell\" + 0.012*\"shoot\" + 0.011*\"leave\" + '\n",
      "  '0.010*\"group\" + 0.010*\"train\" + 0.008*\"fear\" + 0.008*\"jail\" + '\n",
      "  '0.007*\"share\"'),\n",
      " (6,\n",
      "  '0.220*\"war\" + 0.045*\"fund\" + 0.020*\"boost\" + 0.016*\"post\" + 0.009*\"bush\" + '\n",
      "  '0.009*\"fear\" + 0.009*\"howard\" + 0.008*\"anti\" + 0.008*\"memorial\" + '\n",
      "  '0.007*\"crimes\"'),\n",
      " (7,\n",
      "  '0.063*\"bomb\" + 0.039*\"deny\" + 0.032*\"offer\" + 0.022*\"name\" + 0.021*\"boost\" '\n",
      "  '+ 0.018*\"bali\" + 0.015*\"delay\" + 0.013*\"blast\" + 0.011*\"tas\" + '\n",
      "  '0.010*\"school\"'),\n",
      " (8,\n",
      "  '0.071*\"coast\" + 0.064*\"move\" + 0.045*\"iraqi\" + 0.041*\"gold\" + '\n",
      "  '0.031*\"consider\" + 0.026*\"boost\" + 0.022*\"clear\" + 0.019*\"north\" + '\n",
      "  '0.013*\"tas\" + 0.010*\"rain\"'),\n",
      " (9,\n",
      "  '0.223*\"water\" + 0.056*\"restrictions\" + 0.019*\"defend\" + 0.015*\"race\" + '\n",
      "  '0.014*\"rise\" + 0.010*\"work\" + 0.009*\"residents\" + 0.008*\"car\" + '\n",
      "  '0.008*\"rain\" + 0.007*\"irrigators\"'),\n",
      " (10,\n",
      "  '0.186*\"report\" + 0.071*\"seek\" + 0.015*\"fund\" + 0.013*\"highlight\" + '\n",
      "  '0.009*\"case\" + 0.008*\"sars\" + 0.007*\"land\" + 0.007*\"industry\" + '\n",
      "  '0.006*\"reject\" + 0.006*\"north\"'),\n",
      " (11,\n",
      "  '0.237*\"nsw\" + 0.010*\"land\" + 0.009*\"opposition\" + 0.008*\"election\" + '\n",
      "  '0.008*\"rail\" + 0.007*\"north\" + 0.007*\"fight\" + 0.007*\"house\" + '\n",
      "  '0.006*\"storm\" + 0.005*\"oppn\"'),\n",
      " (12,\n",
      "  '0.094*\"hold\" + 0.051*\"drought\" + 0.044*\"consider\" + 0.023*\"meet\" + '\n",
      "  '0.019*\"aid\" + 0.018*\"fight\" + 0.017*\"market\" + 0.014*\"farmers\" + '\n",
      "  '0.013*\"tour\" + 0.010*\"close\"'),\n",
      " (13,\n",
      "  '0.112*\"ban\" + 0.023*\"arrest\" + 0.021*\"return\" + 0.016*\"seek\" + '\n",
      "  '0.016*\"defend\" + 0.010*\"decision\" + 0.009*\"community\" + 0.009*\"action\" + '\n",
      "  '0.009*\"port\" + 0.008*\"former\"'),\n",
      " (14,\n",
      "  '0.168*\"death\" + 0.040*\"rise\" + 0.034*\"fund\" + 0.019*\"service\" + '\n",
      "  '0.014*\"sars\" + 0.013*\"investigate\" + 0.013*\"jail\" + 0.013*\"sentence\" + '\n",
      "  '0.011*\"penalty\" + 0.010*\"offer\"'),\n",
      " (15,\n",
      "  '0.058*\"final\" + 0.033*\"work\" + 0.028*\"green\" + 0.027*\"give\" + 0.022*\"clash\" '\n",
      "  '+ 0.018*\"mp\" + 0.016*\"expect\" + 0.013*\"indigenous\" + 0.010*\"reject\" + '\n",
      "  '0.010*\"fight\"'),\n",
      " (16,\n",
      "  '0.062*\"pay\" + 0.054*\"top\" + 0.034*\"group\" + 0.027*\"rise\" + 0.023*\"bush\" + '\n",
      "  '0.022*\"rain\" + 0.022*\"car\" + 0.021*\"strike\" + 0.010*\"teachers\" + '\n",
      "  '0.010*\"workers\"'),\n",
      " (17,\n",
      "  '0.055*\"rule\" + 0.052*\"aust\" + 0.043*\"change\" + 0.040*\"mp\" + 0.025*\"want\" + '\n",
      "  '0.021*\"farmers\" + 0.021*\"centre\" + 0.019*\"trade\" + 0.009*\"howard\" + '\n",
      "  '0.008*\"troop\"'),\n",
      " (18,\n",
      "  '0.212*\"win\" + 0.015*\"award\" + 0.010*\"title\" + 0.008*\"tour\" + 0.007*\"stage\" '\n",
      "  '+ 0.006*\"top\" + 0.004*\"series\" + 0.004*\"play\" + 0.004*\"race\" + '\n",
      "  '0.003*\"contract\"'),\n",
      " (19,\n",
      "  '0.121*\"urge\" + 0.095*\"concern\" + 0.069*\"air\" + 0.013*\"public\" + '\n",
      "  '0.011*\"service\" + 0.010*\"consider\" + 0.010*\"push\" + 0.007*\"raise\" + '\n",
      "  '0.006*\"residents\" + 0.006*\"group\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data_result.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'china'\n",
    "year = trend2003\n",
    "\n",
    "for i in range(len(year)):\n",
    "    if keyword in year.lemmatize.iloc[i]:\n",
    "        print(year['headline_text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain a NMF model.\n",
    "model = NMF(n_components=num_topics, init='nndsvd');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init='nndsvd', l1_ratio=0.0,\n",
       "  max_iter=200, n_components=10, random_state=None, shuffle=False,\n",
       "  solver='cd', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(xtfidf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 770, 4199,  262,  286, 4008, 3972, 2483,  340, 1778, 1794, 1364,\n",
       "       3503, 4920, 1622, 3006,  795, 1667, 3738, 2486, 2738], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.components_[0].argsort()[:-20 - 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.98983684e-05,\n",
       "       0.00000000e+00, 2.90366825e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.49547581e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.09998539e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.02656925e-03, 5.62309427e-05, 2.86505275e-06, 3.37057920e-03])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.components_[0][:-20 - 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmf_topics(model, n_top_words):\n",
    "    \n",
    "    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n",
    "    feat_names = vectorizer.get_feature_names()\n",
    "    vocabulary = vectorizer.vocabulary_\n",
    "    \n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        \n",
    "        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n",
    "        words_ids = model.components_[i].argsort()[:-20 - 1:-1]\n",
    "        words = [feat_names[key] for key in words_ids]\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words;\n",
    "    \n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charge</td>\n",
       "      <td>plan</td>\n",
       "      <td>govt</td>\n",
       "      <td>face</td>\n",
       "      <td>win</td>\n",
       "      <td>continue</td>\n",
       "      <td>car</td>\n",
       "      <td>warn</td>\n",
       "      <td>soldier</td>\n",
       "      <td>fund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stab</td>\n",
       "      <td>development</td>\n",
       "      <td>nsw</td>\n",
       "      <td>trial</td>\n",
       "      <td>award</td>\n",
       "      <td>death</td>\n",
       "      <td>woman</td>\n",
       "      <td>war</td>\n",
       "      <td>claim</td>\n",
       "      <td>boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assault</td>\n",
       "      <td>consider</td>\n",
       "      <td>urge</td>\n",
       "      <td>death</td>\n",
       "      <td>top</td>\n",
       "      <td>rise</td>\n",
       "      <td>hospital</td>\n",
       "      <td>travel</td>\n",
       "      <td>report</td>\n",
       "      <td>seek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attempt</td>\n",
       "      <td>reject</td>\n",
       "      <td>qld</td>\n",
       "      <td>water</td>\n",
       "      <td>lead</td>\n",
       "      <td>fight</td>\n",
       "      <td>accident</td>\n",
       "      <td>public</td>\n",
       "      <td>shoot</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shoot</td>\n",
       "      <td>water</td>\n",
       "      <td>consider</td>\n",
       "      <td>tough</td>\n",
       "      <td>tour</td>\n",
       "      <td>investigation</td>\n",
       "      <td>fatal</td>\n",
       "      <td>water</td>\n",
       "      <td>baghdad</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sex</td>\n",
       "      <td>house</td>\n",
       "      <td>feed</td>\n",
       "      <td>pair</td>\n",
       "      <td>title</td>\n",
       "      <td>protest</td>\n",
       "      <td>investigate</td>\n",
       "      <td>downer</td>\n",
       "      <td>iraqi</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lay</td>\n",
       "      <td>group</td>\n",
       "      <td>accuse</td>\n",
       "      <td>ban</td>\n",
       "      <td>england</td>\n",
       "      <td>strike</td>\n",
       "      <td>stab</td>\n",
       "      <td>sars</td>\n",
       "      <td>troop</td>\n",
       "      <td>concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bail</td>\n",
       "      <td>management</td>\n",
       "      <td>local</td>\n",
       "      <td>accuse</td>\n",
       "      <td>stage</td>\n",
       "      <td>house</td>\n",
       "      <td>house</td>\n",
       "      <td>power</td>\n",
       "      <td>blast</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fraud</td>\n",
       "      <td>protest</td>\n",
       "      <td>reject</td>\n",
       "      <td>restrictions</td>\n",
       "      <td>race</td>\n",
       "      <td>debate</td>\n",
       "      <td>death</td>\n",
       "      <td>threat</td>\n",
       "      <td>reject</td>\n",
       "      <td>indigenous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>front</td>\n",
       "      <td>power</td>\n",
       "      <td>tas</td>\n",
       "      <td>future</td>\n",
       "      <td>final</td>\n",
       "      <td>clean</td>\n",
       "      <td>shoot</td>\n",
       "      <td>nsw</td>\n",
       "      <td>bomb</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>drop</td>\n",
       "      <td>residents</td>\n",
       "      <td>defend</td>\n",
       "      <td>jail</td>\n",
       "      <td>election</td>\n",
       "      <td>school</td>\n",
       "      <td>bomb</td>\n",
       "      <td>scam</td>\n",
       "      <td>wound</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rape</td>\n",
       "      <td>meet</td>\n",
       "      <td>review</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>return</td>\n",
       "      <td>row</td>\n",
       "      <td>driver</td>\n",
       "      <td>aid</td>\n",
       "      <td>four</td>\n",
       "      <td>urge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>woman</td>\n",
       "      <td>change</td>\n",
       "      <td>move</td>\n",
       "      <td>allege</td>\n",
       "      <td>series</td>\n",
       "      <td>blaze</td>\n",
       "      <td>highway</td>\n",
       "      <td>drivers</td>\n",
       "      <td>war</td>\n",
       "      <td>restrictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fatal</td>\n",
       "      <td>park</td>\n",
       "      <td>support</td>\n",
       "      <td>challenge</td>\n",
       "      <td>gold</td>\n",
       "      <td>pay</td>\n",
       "      <td>arrest</td>\n",
       "      <td>risk</td>\n",
       "      <td>death</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>offences</td>\n",
       "      <td>move</td>\n",
       "      <td>rule</td>\n",
       "      <td>sex</td>\n",
       "      <td>hold</td>\n",
       "      <td>sars</td>\n",
       "      <td>jail</td>\n",
       "      <td>dangers</td>\n",
       "      <td>grenade</td>\n",
       "      <td>drought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>child</td>\n",
       "      <td>public</td>\n",
       "      <td>inquiry</td>\n",
       "      <td>rape</td>\n",
       "      <td>honour</td>\n",
       "      <td>war</td>\n",
       "      <td>collision</td>\n",
       "      <td>health</td>\n",
       "      <td>lead</td>\n",
       "      <td>budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fight</td>\n",
       "      <td>merger</td>\n",
       "      <td>criticise</td>\n",
       "      <td>final</td>\n",
       "      <td>prize</td>\n",
       "      <td>investigations</td>\n",
       "      <td>train</td>\n",
       "      <td>storm</td>\n",
       "      <td>arrest</td>\n",
       "      <td>farmers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>robbery</td>\n",
       "      <td>shire</td>\n",
       "      <td>decision</td>\n",
       "      <td>trio</td>\n",
       "      <td>streak</td>\n",
       "      <td>hunt</td>\n",
       "      <td>leave</td>\n",
       "      <td>ahead</td>\n",
       "      <td>sars</td>\n",
       "      <td>regional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lead</td>\n",
       "      <td>concern</td>\n",
       "      <td>opposition</td>\n",
       "      <td>robbery</td>\n",
       "      <td>company</td>\n",
       "      <td>trade</td>\n",
       "      <td>name</td>\n",
       "      <td>bali</td>\n",
       "      <td>suspect</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>men</td>\n",
       "      <td>green</td>\n",
       "      <td>rail</td>\n",
       "      <td>five</td>\n",
       "      <td>clijsters</td>\n",
       "      <td>work</td>\n",
       "      <td>park</td>\n",
       "      <td>safety</td>\n",
       "      <td>ambush</td>\n",
       "      <td>hospital</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic # 01   Topic # 02  Topic # 03    Topic # 04 Topic # 05  \\\n",
       "0      charge         plan        govt          face        win   \n",
       "1        stab  development         nsw         trial      award   \n",
       "2     assault     consider        urge         death        top   \n",
       "3     attempt       reject         qld         water       lead   \n",
       "4       shoot        water    consider         tough       tour   \n",
       "5         sex        house        feed          pair      title   \n",
       "6         lay        group      accuse           ban    england   \n",
       "7        bail   management       local        accuse      stage   \n",
       "8       fraud      protest      reject  restrictions       race   \n",
       "9       front        power         tas        future      final   \n",
       "10       drop    residents      defend          jail   election   \n",
       "11       rape         meet      review     uncertain     return   \n",
       "12      woman       change        move        allege     series   \n",
       "13      fatal         park     support     challenge       gold   \n",
       "14   offences         move        rule           sex       hold   \n",
       "15      child       public     inquiry          rape     honour   \n",
       "16      fight       merger   criticise         final      prize   \n",
       "17    robbery        shire    decision          trio     streak   \n",
       "18       lead      concern  opposition       robbery    company   \n",
       "19        men        green        rail          five  clijsters   \n",
       "\n",
       "        Topic # 06   Topic # 07 Topic # 08 Topic # 09    Topic # 10  \n",
       "0         continue          car       warn    soldier          fund  \n",
       "1            death        woman        war      claim         boost  \n",
       "2             rise     hospital     travel     report          seek  \n",
       "3            fight     accident     public      shoot         water  \n",
       "4    investigation        fatal      water    baghdad       service  \n",
       "5          protest  investigate     downer      iraqi        health  \n",
       "6           strike         stab       sars      troop       concern  \n",
       "7            house        house      power      blast          rain  \n",
       "8           debate        death     threat     reject    indigenous  \n",
       "9            clean        shoot        nsw       bomb           air  \n",
       "10          school         bomb       scam      wound         group  \n",
       "11             row       driver        aid       four          urge  \n",
       "12           blaze      highway    drivers        war  restrictions  \n",
       "13             pay       arrest       risk      death           job  \n",
       "14            sars         jail    dangers    grenade       drought  \n",
       "15             war    collision     health       lead        budget  \n",
       "16  investigations        train      storm     arrest       farmers  \n",
       "17            hunt        leave      ahead       sars      regional  \n",
       "18           trade         name       bali    suspect        centre  \n",
       "19            work         park     safety     ambush      hospital  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_nmf_topics(model, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
